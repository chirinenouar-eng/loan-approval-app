{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 3 - Nettoyage et Feature Engineering\n",
    "## Mast√®re 2 - Data & Intelligence Artificielle\n",
    "\n",
    "**Dur√©e** : 45 minutes\n",
    "\n",
    "### Objectifs\n",
    "1. Traiter les valeurs manquantes (strat√©gie m√©diane/mode)\n",
    "2. D√©tecter et traiter les outliers (m√©thode IQR et capping)\n",
    "3. Cr√©er des features m√©tier pertinentes :\n",
    "   - TotalIncome\n",
    "   - LoanAmountToIncome\n",
    "   - EMI (mensualit√©)\n",
    "   - EMIToIncome\n",
    "   - Transformations logarithmiques\n",
    "4. Encoder les variables cat√©gorielles\n",
    "5. Sauvegarder le dataset nettoy√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports r√©ussis\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/loan_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Charger le dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/raw/loan_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDATASET INITIAL\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glenn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glenn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glenn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glenn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glenn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/raw/loan_data.csv'"
     ]
    }
   ],
   "source": [
    "# Charger le dataset\n",
    "df = pd.read_csv('../data/raw/loan_data.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET INITIAL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Dimensions : {df.shape}\")\n",
    "print(f\"\\nValeurs manquantes :\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Cr√©er une copie pour le travail\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"\\n‚úÖ Dataset charg√© et copi√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üö® IMPORTANT : Supprimer la colonne Loan_ID (identifiant sans pouvoir pr√©dictif)\n",
    "if 'Loan_ID' in df_clean.columns:\n",
    "    print(\"\\n‚ö†Ô∏è Colonne 'Loan_ID' d√©tect√©e\")\n",
    "    print(\"   ‚Üí C'est un identifiant unique sans pouvoir pr√©dictif\")\n",
    "    print(\"   ‚Üí L'inclure causerait du data leakage et un overfitting\")\n",
    "    df_clean = df_clean.drop('Loan_ID', axis=1)\n",
    "    print(\"   ‚úÖ Loan_ID supprim√©e\")\n",
    "    print(f\"   Nouvelles dimensions : {df_clean.shape}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Pas de colonne Loan_ID d√©tect√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß √âTAPE 1 : Traitement des valeurs manquantes\n",
    "\n",
    "### Strat√©gie\n",
    "- **Variables num√©riques** : Imputer avec la **m√©diane** (robuste aux outliers)\n",
    "- **Variables cat√©gorielles** : Imputer avec le **mode** (valeur la plus fr√©quente)\n",
    "\n",
    "### Pourquoi la m√©diane plut√¥t que la moyenne ?\n",
    "La m√©diane n'est pas influenc√©e par les valeurs extr√™mes. Par exemple, si les revenus sont [1000, 2000, 3000, 100000], la moyenne (26500) est tir√©e vers le haut par 100000, alors que la m√©diane (2500) est plus repr√©sentative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âTAPE 1 : TRAITEMENT DES VALEURS MANQUANTES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# D√©finir les colonnes num√©riques et cat√©gorielles\n",
    "numerical_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', \n",
    "                  'Loan_Amount_Term', 'Credit_History']\n",
    "categorical_cols = ['Gender', 'Married', 'Dependents', 'Education', \n",
    "                    'Self_Employed', 'Property_Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation des variables num√©riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Imputer les valeurs manquantes num√©riques avec la m√©diane\n",
    "for col in numerical_cols:\n",
    "    if col in df_clean.columns and df_clean[col].isnull().sum() > 0:\n",
    "        median_value = df_clean[col].median()\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        \n",
    "        # Remplir les NaN avec la m√©diane\n",
    "        df_clean[col].fillna(median_value, inplace=True)\n",
    "        \n",
    "        print(f\"‚úÖ {col}: {missing_count} NaN remplac√©s par la m√©diane ({median_value:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation des variables cat√©gorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Imputer les valeurs manquantes cat√©gorielles avec le mode\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns and df_clean[col].isnull().sum() > 0:\n",
    "        mode_value = df_clean[col].mode()[0]\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        \n",
    "        # Remplir les NaN avec le mode\n",
    "        df_clean[col].fillna(mode_value, inplace=True)\n",
    "        \n",
    "        print(f\"‚úÖ {col}: {missing_count} NaN remplac√©s par le mode ('{mode_value}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification finale\n",
    "print(f\"\\n‚úÖ Total de valeurs manquantes apr√®s imputation : {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ √âTAPE 2 : D√©tection et traitement des outliers\n",
    "\n",
    "### Qu'est-ce qu'un outlier ?\n",
    "Une valeur **aberrante** qui s'√©carte fortement des autres observations. Les outliers peuvent :\n",
    "- √ätre des **erreurs de saisie** (revenu de 1 000 000 000‚Ç¨)\n",
    "- √ätre des **valeurs r√©elles** mais extr√™mes (PDG avec tr√®s haut salaire)\n",
    "- **Fausser les mod√®les** ML sensibles aux valeurs extr√™mes\n",
    "\n",
    "### M√©thode IQR (InterQuartile Range)\n",
    "- **Q1** : Premier quartile (25% des donn√©es)\n",
    "- **Q3** : Troisi√®me quartile (75% des donn√©es)\n",
    "- **IQR** : Q3 - Q1\n",
    "- **Outliers** : Valeurs < Q1 - 1.5√óIQR ou > Q3 + 1.5√óIQR\n",
    "\n",
    "### Notre approche : Capping\n",
    "Au lieu de **supprimer** les outliers (perte d'information), nous allons les **plafonner** (capping) aux percentiles 1% et 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des outliers AVANT traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âTAPE 2 : D√âTECTION ET TRAITEMENT DES OUTLIERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cr√©er les boxplots pour visualiser les outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('D√©tection des outliers - AVANT traitement', fontsize=16, fontweight='bold')\n",
    "\n",
    "outlier_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\n",
    "\n",
    "for idx, col in enumerate(outlier_cols):\n",
    "    row = idx // 2\n",
    "    col_idx = idx % 2\n",
    "    \n",
    "    # Boxplot\n",
    "    axes[row, col_idx].boxplot(df_clean[col].dropna(), vert=True)\n",
    "    axes[row, col_idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[row, col_idx].set_ylabel('Valeur')\n",
    "    axes[row, col_idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Calculer les statistiques d'outliers\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    n_outliers = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()\n",
    "    axes[row, col_idx].text(0.5, 0.95, f'Outliers: {n_outliers}', \n",
    "                           transform=axes[row, col_idx].transAxes,\n",
    "                           ha='center', va='top', fontsize=10,\n",
    "                           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Supprimer le dernier subplot vide\n",
    "fig.delaxes(axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outliers_before.png', dpi=300, bbox_inches='tight')\n",
    "print(\"üìä Graphique 'outliers_before.png' sauvegard√©\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de capping (plafonnement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Impl√©menter la fonction de capping\n",
    "def cap_outliers(df, column, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"\n",
    "    Plafonne les valeurs extr√™mes en utilisant des percentiles\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        column: Nom de la colonne\n",
    "        lower_percentile: Percentile inf√©rieur (d√©faut: 1%)\n",
    "        upper_percentile: Percentile sup√©rieur (d√©faut: 99%)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec valeurs plafonn√©es\n",
    "    \"\"\"\n",
    "    lower_bound = df[column].quantile(lower_percentile / 100)\n",
    "    upper_bound = df[column].quantile(upper_percentile / 100)\n",
    "    \n",
    "    # Compter les valeurs plafonn√©es\n",
    "    n_capped_lower = (df[column] < lower_bound).sum()\n",
    "    n_capped_upper = (df[column] > upper_bound).sum()\n",
    "    \n",
    "    # Appliquer le capping\n",
    "    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    if n_capped_lower + n_capped_upper > 0:\n",
    "        print(f\"‚úÖ {column}: {n_capped_lower} valeurs plafonn√©es en bas, \"\n",
    "              f\"{n_capped_upper} en haut (percentiles {lower_percentile}-{upper_percentile})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Fonction cap_outliers cr√©√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application du capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le capping sur les revenus\n",
    "for col in ['ApplicantIncome', 'CoapplicantIncome']:\n",
    "    df_clean = cap_outliers(df_clean, col, lower_percentile=1, upper_percentile=99)\n",
    "\n",
    "# Pour LoanAmount, utiliser des percentiles plus conservateurs\n",
    "df_clean = cap_outliers(df_clean, 'LoanAmount', lower_percentile=0, upper_percentile=95)\n",
    "\n",
    "print(\"\\n‚úÖ Capping appliqu√© sur toutes les variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è √âTAPE 3 : Feature Engineering\n",
    "\n",
    "Le **feature engineering** consiste √† cr√©er de nouvelles variables (features) √† partir des variables existantes pour am√©liorer la performance du mod√®le.\n",
    "\n",
    "### Pourquoi c'est important ?\n",
    "Les mod√®les ML ne peuvent pas \"deviner\" les relations complexes. Par exemple :\n",
    "- Le mod√®le voit `ApplicantIncome` et `LoanAmount` s√©par√©ment\n",
    "- Mais le **ratio** `LoanAmount / Income` est plus informatif (c'est le taux d'endettement !)\n",
    "\n",
    "### Features que nous allons cr√©er :\n",
    "1. **TotalIncome** : Revenu du m√©nage (applicant + coapplicant)\n",
    "2. **LoanAmountToIncome** : Ratio d'endettement\n",
    "3. **EMI** : Mensualit√© estim√©e (Equated Monthly Installment)\n",
    "4. **EMIToIncome** : Part du revenu consacr√©e au remboursement\n",
    "5. **Log_LoanAmount** : Transformation log (r√©duit l'asym√©trie)\n",
    "6. **Log_TotalIncome** : Transformation log\n",
    "7. **Has_Coapplicant** : Indicateur binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âTAPE 3 : FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1 : Revenu total du m√©nage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Cr√©er TotalIncome\n",
    "df_clean['TotalIncome'] = df_clean['ApplicantIncome'] + df_clean['CoapplicantIncome']\n",
    "print(f\"‚úÖ Feature cr√©√©e : TotalIncome (moyenne: {df_clean['TotalIncome'].mean():.2f}‚Ç¨)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2 : Ratio d'endettement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Cr√©er LoanAmountToIncome (√©viter division par z√©ro)\n",
    "df_clean['LoanAmountToIncome'] = df_clean['LoanAmount'] / (df_clean['TotalIncome'] + 1)\n",
    "print(f\"‚úÖ Feature cr√©√©e : LoanAmountToIncome (moyenne: {df_clean['LoanAmountToIncome'].mean():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 3 : EMI (Mensualit√©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Calculer la mensualit√© estim√©e\n",
    "# Formule simplifi√©e : EMI = LoanAmount / Loan_Amount_Term\n",
    "df_clean['EMI'] = df_clean['LoanAmount'] / df_clean['Loan_Amount_Term']\n",
    "print(f\"‚úÖ Feature cr√©√©e : EMI (moyenne: {df_clean['EMI'].mean():.2f}‚Ç¨/mois)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 4 : Ratio EMI sur revenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Cr√©er EMIToIncome\n",
    "df_clean['EMIToIncome'] = df_clean['EMI'] / (df_clean['TotalIncome'] + 1)\n",
    "print(f\"‚úÖ Feature cr√©√©e : EMIToIncome (moyenne: {df_clean['EMIToIncome'].mean():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 5 & 6 : Transformations logarithmiques\n",
    "\n",
    "**Pourquoi le logarithme ?**\n",
    "- R√©duit l'asym√©trie des distributions (skewness)\n",
    "- Ram√®ne les grandes valeurs vers des √©chelles plus g√©rables\n",
    "- Am√©liore souvent la performance des mod√®les lin√©aires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Appliquer log sur les variables asym√©triques\n",
    "df_clean['Log_LoanAmount'] = np.log(df_clean['LoanAmount'] + 1)\n",
    "df_clean['Log_TotalIncome'] = np.log(df_clean['TotalIncome'] + 1)\n",
    "\n",
    "print(f\"‚úÖ Features cr√©√©es : Log_LoanAmount, Log_TotalIncome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 7 : Indicateur de co-demandeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Cr√©er une variable binaire indiquant la pr√©sence d'un co-demandeur\n",
    "df_clean['Has_Coapplicant'] = (df_clean['CoapplicantIncome'] > 0).astype(int)\n",
    "print(f\"‚úÖ Feature cr√©√©e : Has_Coapplicant \"\n",
    "      f\"({df_clean['Has_Coapplicant'].sum()} personnes avec co-demandeur)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des nouvelles features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les nouvelles features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Nouvelles features cr√©√©es', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Distribution TotalIncome\n",
    "axes[0, 0].hist(df_clean['TotalIncome'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Total Income Distribution')\n",
    "axes[0, 0].set_xlabel('Total Income (‚Ç¨)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Distribution LoanAmountToIncome\n",
    "axes[0, 1].hist(df_clean['LoanAmountToIncome'], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Loan Amount to Income Ratio')\n",
    "axes[0, 1].set_xlabel('Ratio')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Distribution EMI\n",
    "axes[1, 0].hist(df_clean['EMI'], bins=30, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('EMI Distribution')\n",
    "axes[1, 0].set_xlabel('EMI (‚Ç¨/month)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# EMIToIncome vs Loan_Status\n",
    "if 'Loan_Status' in df_clean.columns:\n",
    "    df_clean.boxplot(column='EMIToIncome', by='Loan_Status', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('EMI to Income Ratio by Loan Status')\n",
    "    axes[1, 1].set_xlabel('Loan Status')\n",
    "    axes[1, 1].set_ylabel('EMI to Income Ratio')\n",
    "    plt.suptitle('')  # Supprimer le titre automatique du boxplot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('new_features.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nüìä Graphique 'new_features.png' sauvegard√©\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî§ √âTAPE 4 : Encodage des variables cat√©gorielles\n",
    "\n",
    "Les mod√®les ML ne comprennent que les nombres. Il faut donc **encoder** les variables cat√©gorielles.\n",
    "\n",
    "### Deux m√©thodes :\n",
    "\n",
    "#### 1. Label Encoding\n",
    "- Pour variables **ordinales** (avec un ordre logique)\n",
    "- Exemple : Education (Graduate > Not Graduate)\n",
    "- Transforme en : 0, 1, 2...\n",
    "\n",
    "#### 2. One-Hot Encoding\n",
    "- Pour variables **nominales** (sans ordre)\n",
    "- Exemple : Property_Area (Urban, Rural, Semiurban)\n",
    "- Transforme en : colonnes binaires (Area_Urban, Area_Rural...)\n",
    "\n",
    "**‚ö†Ô∏è Attention** : One-Hot avec `drop_first=True` √©vite la multicolin√©arit√© (dummy variable trap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âTAPE 4 : ENCODAGE DES VARIABLES CAT√âGORIELLES\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding pour variables ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Encoder Education (Graduate = 1, Not Graduate = 0)\n",
    "if 'Education' in df_clean.columns:\n",
    "    df_clean['Education'] = df_clean['Education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
    "    print(\"‚úÖ Education encod√©e : Graduate=1, Not Graduate=0\")\n",
    "\n",
    "# TODO : Encoder Loan_Status (Y = 1, N = 0)\n",
    "if 'Loan_Status' in df_clean.columns:\n",
    "    df_clean['Loan_Status'] = df_clean['Loan_Status'].map({'Y': 1, 'N': 0})\n",
    "    print(\"‚úÖ Loan_Status encod√©e : Y=1, N=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding pour variables nominales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Encoder Property_Area (Dummy variables)\n",
    "if 'Property_Area' in df_clean.columns:\n",
    "    df_clean = pd.get_dummies(df_clean, columns=['Property_Area'], prefix='Area', drop_first=True)\n",
    "    print(\"‚úÖ Property_Area encod√©e (One-Hot) : Area_Semiurban, Area_Urban\")\n",
    "\n",
    "# TODO : Encoder Gender\n",
    "if 'Gender' in df_clean.columns:\n",
    "    df_clean = pd.get_dummies(df_clean, columns=['Gender'], prefix='Gender', drop_first=True)\n",
    "    print(\"‚úÖ Gender encod√©e (One-Hot) : Gender_Male\")\n",
    "\n",
    "# TODO : Encoder Married\n",
    "if 'Married' in df_clean.columns:\n",
    "    df_clean = pd.get_dummies(df_clean, columns=['Married'], prefix='Married', drop_first=True)\n",
    "    print(\"‚úÖ Married encod√©e (One-Hot) : Married_Yes\")\n",
    "\n",
    "# TODO : Encoder Self_Employed\n",
    "if 'Self_Employed' in df_clean.columns:\n",
    "    df_clean = pd.get_dummies(df_clean, columns=['Self_Employed'], prefix='SelfEmployed', drop_first=True)\n",
    "    print(\"‚úÖ Self_Employed encod√©e (One-Hot) : SelfEmployed_Yes\")\n",
    "\n",
    "# TODO : Encoder Dependents\n",
    "if 'Dependents' in df_clean.columns:\n",
    "    # Convertir '3+' en 3 pour traiter comme num√©rique\n",
    "    df_clean['Dependents'] = df_clean['Dependents'].replace('3+', '3').astype(float)\n",
    "    print(\"‚úÖ Dependents convertie en num√©rique (3+ ‚Üí 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ √âTAPE 5 : V√©rifications finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âTAPE 5 : V√âRIFICATIONS FINALES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# V√©rifier qu'il n'y a plus de NaN\n",
    "print(f\"\\n‚úÖ Valeurs manquantes restantes : {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier les types de donn√©es\n",
    "print(f\"\\n‚úÖ Types de donn√©es apr√®s nettoyage :\")\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les dimensions finales\n",
    "print(f\"\\n‚úÖ Dimensions finales : {df_clean.shape}\")\n",
    "print(f\"   ‚Üí {df_clean.shape[0]} lignes\")\n",
    "print(f\"   ‚Üí {df_clean.shape[1]} colonnes (vs {df.shape[1]} initialement)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premi√®res lignes\n",
    "print(f\"\\n‚úÖ Aper√ßu du dataset nettoy√© :\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "print(f\"\\n‚úÖ Statistiques descriptives :\")\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ √âTAPE 6 : Sauvegarde du dataset nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âTAPE 6 : SAUVEGARDE DU DATASET NETTOY√â\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# TODO : Sauvegarder le dataset nettoy√©\n",
    "output_file = '../data/processed/loan_data_clean.csv'\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset nettoy√© sauvegard√© dans '{output_file}'\")\n",
    "print(f\"   Pr√™t pour l'√©tape de mod√©lisation !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä R√©capitulatif du nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä R√âCAPITULATIF DU NETTOYAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ Valeurs manquantes trait√©es : {df.isnull().sum().sum()} ‚Üí 0\n",
    "‚úÖ Outliers trait√©s : Capping appliqu√© sur revenus et montants\n",
    "‚úÖ Features cr√©√©es : \n",
    "   - TotalIncome\n",
    "   - LoanAmountToIncome\n",
    "   - EMI\n",
    "   - EMIToIncome\n",
    "   - Log_LoanAmount\n",
    "   - Log_TotalIncome\n",
    "   - Has_Coapplicant\n",
    "‚úÖ Encodage effectu√© :\n",
    "   - Label Encoding : Education, Loan_Status\n",
    "   - One-Hot Encoding : Property_Area, Gender, Married, Self_Employed\n",
    "   - Conversion num√©rique : Dependents\n",
    "‚úÖ Dataset final : {df_clean.shape[0]} lignes √ó {df_clean.shape[1]} colonnes\n",
    "\n",
    "Le dataset est maintenant pr√™t pour l'entra√Ænement du mod√®le ! üöÄ\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Conclusion du TP\n",
    "\n",
    "### Ce que vous avez appris\n",
    "‚úÖ Traiter les valeurs manquantes avec des strat√©gies appropri√©es  \n",
    "‚úÖ D√©tecter et traiter les outliers avec la m√©thode IQR  \n",
    "‚úÖ Cr√©er des features m√©tier pertinentes (feature engineering)  \n",
    "‚úÖ Encoder les variables cat√©gorielles (Label + One-Hot)  \n",
    "‚úÖ Pr√©parer un dataset propre pour le machine learning  \n",
    "\n",
    "### Prochaines √©tapes\n",
    "Dans le **TP 4**, nous allons :\n",
    "- Entra√Æner un mod√®le de classification (R√©gression Logistique)\n",
    "- √âvaluer la performance avec plusieurs m√©triques\n",
    "- Cr√©er des visualisations (matrice de confusion, courbe ROC)\n",
    "- Identifier les features les plus importantes\n",
    "\n",
    "### Points cl√©s √† retenir\n",
    "1. **Toujours v√©rifier les NaN** avant de mod√©liser\n",
    "2. **Outliers ‚â† Erreurs** : parfois ce sont des valeurs r√©elles\n",
    "3. **Feature engineering > Algorithmes complexes** : de bonnes features font la diff√©rence\n",
    "4. **Encoder intelligemment** : ordinale vs nominale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
